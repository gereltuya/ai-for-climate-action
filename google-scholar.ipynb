{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4025a93d",
   "metadata": {},
   "source": [
    "# Google Scholar paper collection\n",
    "\n",
    "### To run this notebook, you need to install the following packages:\n",
    "\n",
    "- ```google-search-results``` ([SerpAPI](https://serpapi.com/) key is also needed.)\n",
    "- ```pandas```\n",
    "- ```matplotlib```\n",
    "- ```networkx```\n",
    "- ```python-slugify```\n",
    "\n",
    "### The notebook is sectioned into the following parts:\n",
    "\n",
    "- [Metadata collection](#Metadata-collection)\n",
    "- [Metadata exploration](#Metadata-exploration)\n",
    "- [Fulltext collection](#Fulltext-collection)\n",
    "- [Unavailable papers](#Unavailable-papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9489fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata collection\n",
    "\n",
    "import json\n",
    "from serpapi import GoogleSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata exploration\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fulltext collection\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "import urllib.request as ur\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3d773",
   "metadata": {},
   "source": [
    "## Metadata collection\n",
    "\n",
    "- [Back to top](#Google-Scholar-paper-collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d74e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting metadata of Google Scholar papers\n",
    "\n",
    "for i in range(0, 49): # Maximum of 980 papers were available at the time of request (2022/11/21)\n",
    "    start_page = i*20\n",
    "\n",
    "    params = {\n",
    "      \"api_key\": \"\", # Removed key for security reasons\n",
    "      \"device\": \"desktop\",\n",
    "      \"engine\": \"google_scholar\",\n",
    "      \"q\": \"artificial intelligence climate change\",\n",
    "      \"hl\": \"en\",\n",
    "      \"scisbd\": \"0\",\n",
    "      \"num\": \"20\",\n",
    "      \"start\": str(start_page)\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    \n",
    "    results_filename = \"./data/google-scholar/metadata/results\" + str(i) + \".json\"\n",
    "    \n",
    "    with open(results_filename, \"w\") as results_file:\n",
    "        json.dump(results, results_file)\n",
    "    \n",
    "    print(\"printed:\" + results_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca729539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing results by filtering out papers with authors, and summary\n",
    "\n",
    "organic_results = []\n",
    "organic_results_authors = []\n",
    "organic_results_summary = []\n",
    "\n",
    "for i in range(0, 49):\n",
    "    start_page = i*20\n",
    "    results_filename = \"./data/google-scholar/metadata/results\" + str(i) + \".json\"\n",
    "\n",
    "    with open(results_filename) as results_file:\n",
    "        results_dict = json.load(results_file)\n",
    "\n",
    "    for j in range(len(results_dict[\"organic_results\"])):\n",
    "        results_dict[\"organic_results\"][j][\"position\"] = start_page + j\n",
    "        organic_results.append(results_dict[\"organic_results\"][j])\n",
    "        \n",
    "        if len(results_dict[\"organic_results\"][j][\"publication_info\"]) > 1:\n",
    "            organic_results_authors.append(results_dict[\"organic_results\"][j])\n",
    "            print(\"added paper no.\", str(start_page + j), \"to authors\")\n",
    "        else:\n",
    "            organic_results_summary.append(results_dict[\"organic_results\"][j])\n",
    "            print(\"added paper no.\", str(start_page + j), \"to summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ff5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving organic results for later use\n",
    "\n",
    "with open(\"./data/google-scholar/metadata/google-scholar.json\", \"w\") as or_filename:\n",
    "    json.dump(organic_results, or_filename, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening nested data for papers and getting unique authors\n",
    "\n",
    "papers = []\n",
    "authors = {}\n",
    "\n",
    "for i in range(len(organic_results)):\n",
    "    print(\"---> started analyzing paper no.\", str(i))\n",
    "    paper = {}\n",
    "    \n",
    "    paper[\"position\"] = organic_results[i][\"position\"]\n",
    "    paper[\"title\"] = organic_results[i][\"title\"]\n",
    "    paper[\"result_id\"] = organic_results[i][\"result_id\"]\n",
    "    \n",
    "    if \"link\" in organic_results[i].keys():\n",
    "        paper[\"link\"] = organic_results[i][\"link\"]\n",
    "\n",
    "    paper[\"snippet\"] = organic_results[i][\"snippet\"]\n",
    "    \n",
    "    paper[\"pi_summary\"] = organic_results[i][\"publication_info\"][\"summary\"]\n",
    "    author_names = []\n",
    "    author_links = []\n",
    "    author_serpapi_scholar_links = []\n",
    "    author_author_ids = []\n",
    "    author_count = 0\n",
    "    \n",
    "    if len(organic_results[i][\"publication_info\"]) > 1:\n",
    "        for j in range(len(organic_results[i][\"publication_info\"][\"authors\"])):\n",
    "            author_names.append(organic_results[i][\"publication_info\"][\"authors\"][j][\"name\"])\n",
    "            author_links.append(organic_results[i][\"publication_info\"][\"authors\"][j][\"link\"])\n",
    "            author_serpapi_scholar_links.append(organic_results[i][\"publication_info\"][\"authors\"][j][\"serpapi_scholar_link\"])\n",
    "            author_author_ids.append(organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"])\n",
    "            \n",
    "            if organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"] not in authors.keys():\n",
    "                author = {}\n",
    "            \n",
    "                author[\"name\"] = organic_results[i][\"publication_info\"][\"authors\"][j][\"name\"]\n",
    "                author[\"link\"] = organic_results[i][\"publication_info\"][\"authors\"][j][\"link\"]\n",
    "                author[\"serpapi_scholar_link\"] = organic_results[i][\"publication_info\"][\"authors\"][j][\"serpapi_scholar_link\"]\n",
    "                author[\"author_id\"] = organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"]\n",
    "                author[\"papers\"] = []\n",
    "                \n",
    "                authors[organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"]] = author\n",
    "                \n",
    "                print(\"new author\", organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"], \"added at no.\", str(len(authors)))\n",
    "            \n",
    "            author_paper = {}\n",
    "                \n",
    "            author_paper[\"position\"] = organic_results[i][\"position\"]\n",
    "            author_paper[\"result_id\"] = organic_results[i][\"result_id\"]\n",
    "            author_paper[\"authorship_order\"] = j\n",
    "            \n",
    "            authors[organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"]][\"papers\"].append(author_paper)\n",
    "                \n",
    "            print(\"new paper no.\", str(organic_results[i][\"position\"]), \"added to the author\", organic_results[i][\"publication_info\"][\"authors\"][j][\"author_id\"])\n",
    "            \n",
    "        author_count = len(organic_results[i][\"publication_info\"][\"authors\"])\n",
    "            \n",
    "    paper[\"pi_author_names\"] = author_names\n",
    "    paper[\"pi_author_links\"] = author_links\n",
    "    paper[\"pi_author_serpapi_scholar_links\"] = author_serpapi_scholar_links\n",
    "    paper[\"pi_author_author_ids\"] = author_author_ids\n",
    "    paper[\"pi_author_count\"] = author_count\n",
    "    \n",
    "    resource_titles = []\n",
    "    resource_file_formats = []\n",
    "    resource_links = []\n",
    "    \n",
    "    if \"resources\" in organic_results[i].keys():\n",
    "        for k in range(len(organic_results[i][\"resources\"])):\n",
    "            resource_titles.append(organic_results[i][\"resources\"][k][\"title\"])\n",
    "            resource_links.append(organic_results[i][\"resources\"][k][\"link\"])\n",
    "            if \"file_format\" in organic_results[i][\"resources\"][k].keys():\n",
    "                resource_file_formats.append(organic_results[i][\"resources\"][k][\"file_format\"])\n",
    "    \n",
    "    paper[\"r_title\"] = resource_titles\n",
    "    paper[\"r_file_format\"] = resource_file_formats\n",
    "    paper[\"r_link\"] = resource_links\n",
    "    \n",
    "    paper[\"il_serpapi_cite_link\"] = organic_results[i][\"inline_links\"][\"serpapi_cite_link\"]\n",
    "    \n",
    "    if \"cited_by\" in organic_results[i][\"inline_links\"].keys():\n",
    "        paper[\"il_cb_total\"] = organic_results[i][\"inline_links\"][\"cited_by\"][\"total\"]\n",
    "        paper[\"il_cb_link\"] = organic_results[i][\"inline_links\"][\"cited_by\"][\"link\"]\n",
    "        \n",
    "        if \"cites_id\" in organic_results[i][\"inline_links\"][\"cited_by\"].keys():\n",
    "            paper[\"il_cb_cites_id\"] = organic_results[i][\"inline_links\"][\"cited_by\"][\"cites_id\"]\n",
    "            \n",
    "        if \"serpapi_scholar_link\" in organic_results[i][\"inline_links\"][\"cited_by\"].keys():\n",
    "            paper[\"il_cb_serpapi_scholar_link\"] = organic_results[i][\"inline_links\"][\"cited_by\"][\"serpapi_scholar_link\"]\n",
    "    \n",
    "    if \"related_pages_link\" in organic_results[i][\"inline_links\"].keys():\n",
    "        paper[\"il_related_pages_link\"] = organic_results[i][\"inline_links\"][\"related_pages_link\"]\n",
    "\n",
    "    if \"serpapi_related_pages_link\" in organic_results[i][\"inline_links\"].keys():\n",
    "        paper[\"il_serpapi_related_pages_link\"] = organic_results[i][\"inline_links\"][\"serpapi_related_pages_link\"]\n",
    "    \n",
    "    if \"versions\" in organic_results[i][\"inline_links\"].keys():\n",
    "        paper[\"il_v_total\"] = organic_results[i][\"inline_links\"][\"versions\"][\"total\"]\n",
    "        paper[\"il_v_link\"] = organic_results[i][\"inline_links\"][\"versions\"][\"link\"]\n",
    "        paper[\"il_v_cluster_id\"] = organic_results[i][\"inline_links\"][\"versions\"][\"cluster_id\"]\n",
    "        paper[\"il_v_serpapi_scholar_link\"] = organic_results[i][\"inline_links\"][\"versions\"][\"serpapi_scholar_link\"]\n",
    "    \n",
    "    papers.append(paper)\n",
    "    \n",
    "    print(\"new paper\", str(organic_results[i][\"position\"]), \"added\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec7269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichening authors data\n",
    "\n",
    "authors_list = []\n",
    "\n",
    "for key in authors.keys():\n",
    "    authors[key][\"paper_count\"] = len(authors[key][\"papers\"])\n",
    "    \n",
    "    paper_positions = []\n",
    "    paper_result_ids = []\n",
    "    paper_authorship_orders = []\n",
    "    \n",
    "    for i in range(len(authors[key][\"papers\"])):\n",
    "        paper_positions.append(authors[key][\"papers\"][i][\"position\"])\n",
    "        paper_result_ids.append(authors[key][\"papers\"][i][\"result_id\"])\n",
    "        paper_authorship_orders.append(authors[key][\"papers\"][i][\"authorship_order\"])\n",
    "        \n",
    "    authors[key][\"paper_positions\"] = paper_positions\n",
    "    authors[key][\"paper_result_ids\"] = paper_result_ids\n",
    "    authors[key][\"paper_authorship_orders\"] = paper_authorship_orders\n",
    "    \n",
    "    authors[key].pop(\"papers\", None)\n",
    "    \n",
    "    authors_list.append(authors[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9949670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving papers metadata for later use\n",
    "\n",
    "with open(\"./data/google-scholar/metadata/google-scholar-papers.json\", \"w\") as papers_filename:\n",
    "    json.dump(papers, papers_filename, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79199c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111cbd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving authors metadata for later use\n",
    "\n",
    "with open(\"./data/google-scholar/metadata/google-scholar-authors.json\", \"w\") as authors_filename:\n",
    "    json.dump(authors_list, authors_filename, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05402b20",
   "metadata": {},
   "source": [
    "## Metadata exploration\n",
    "\n",
    "- [Back to top](#Google-Scholar-paper-collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04de270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading saved data\n",
    "\n",
    "authors_df = pd.read_json(\"./data/google-scholar/metadata/google-scholar-authors.json\")\n",
    "papers_df = pd.read_json(\"./data/google-scholar/metadata/google-scholar-papers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(authors_df[\"author_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate pairs\n",
    "\n",
    "duplicate_pairs = []\n",
    "\n",
    "for d in papers_duplicates:\n",
    "    pair = []\n",
    "    for p in papers:\n",
    "        if p[\"title\"] == d:\n",
    "            pair.append(p[\"position\"])\n",
    "    duplicate_pairs.append(pair)\n",
    "    \n",
    "duplicate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking different features of duplicate titles\n",
    "\n",
    "for dp in duplicate_pairs[:1]:\n",
    "    x = papers[dp[0]]\n",
    "    y = papers[dp[1]]\n",
    "    diff = {k: x[k] for k in x if k not in y or x[k] != y[k]}\n",
    "    print(diff.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca637a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out unique titles with listed authors\n",
    "\n",
    "papers_df_uniques = papers_df.groupby(\"title\",sort=False).max().sort_values(\"pi_author_count\", ascending=False)\n",
    "\n",
    "papers_w_authors = papers_df_uniques[papers_df_uniques[\"pi_author_count\"] > 0]\n",
    "\n",
    "papers_w_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating connections between authors and papers\n",
    "\n",
    "connections = []\n",
    "\n",
    "for i in range(len(papers_w_authors)):\n",
    "    for j in range(len(papers_w_authors[\"pi_author_author_ids\"][i])):\n",
    "        connection = {}\n",
    "        connection[\"paper_id\"] = papers_w_authors[\"result_id\"][i]\n",
    "        connection[\"author_id\"] = papers_w_authors[\"pi_author_author_ids\"][i][j]\n",
    "        connections.append(connection)\n",
    "        \n",
    "len(connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out unique authors from connections\n",
    "\n",
    "authors_dict = {}\n",
    "\n",
    "for i in range(len(connections)):\n",
    "    if connections[i][\"author_id\"] not in authors_dict.keys():\n",
    "        authors_dict[connections[i][\"author_id\"]] = []\n",
    "    authors_dict[connections[i][\"author_id\"]].append(connections[i][\"paper_id\"])\n",
    "    \n",
    "len(authors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f944ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating connections between papers written by the same authors\n",
    "\n",
    "paper_pairs = []\n",
    "\n",
    "for i in range(len(connections)):\n",
    "    for j in range(len(authors_dict[connections[i][\"author_id\"]])):\n",
    "        paper_pair = {}\n",
    "        paper_pair[\"paper_1\"] = connections[i][\"paper_id\"]\n",
    "        paper_pair[\"paper_2\"] = authors_dict[connections[i][\"author_id\"]][j]\n",
    "        if paper_pair[\"paper_1\"] != paper_pair[\"paper_2\"]:\n",
    "            paper_pairs.append(paper_pair)\n",
    "\n",
    "len(paper_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e01b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_df = pd.DataFrame.from_records(paper_pairs)\n",
    "\n",
    "collab_df = collab_df.groupby([\"paper_1\", \"paper_2\"]).agg({\"paper_1\": [\"count\"]}).reset_index()\n",
    "\n",
    "collab_df.columns = [\"paper_1\", \"paper_2\", \"common_authors\"]\n",
    "\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting authors who worked on same papers\n",
    "\n",
    "author_pairs = []\n",
    "\n",
    "for i in range(len(papers_w_authors)):\n",
    "    for j in range(len(papers_w_authors[\"pi_author_author_ids\"][i])):\n",
    "        for k in range(j+1, len(papers_w_authors[\"pi_author_author_ids\"][i])):\n",
    "            author_pair = {}\n",
    "            author_pair[\"author_1\"] = papers_w_authors[\"pi_author_author_ids\"][i][j]\n",
    "            author_pair[\"author_2\"] = papers_w_authors[\"pi_author_author_ids\"][i][k]\n",
    "            author_pairs.append(author_pair)\n",
    "        \n",
    "len(author_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_df = pd.DataFrame.from_records(author_pairs)\n",
    "\n",
    "collab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating graph from papers that have authors in common\n",
    "\n",
    "collab_graph = nx.from_pandas_edgelist(collab_df, \"paper_1\", \"paper_2\", edge_attr = \"common_authors\", create_using = nx.DiGraph())\n",
    "\n",
    "print(nx.info(collab_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(20, 20))\n",
    "layout = nx.spring_layout(collab_graph, k = 0.7)\n",
    "\n",
    "nx.draw_networkx_edges(collab_graph, layout, edge_color = '#AAAAAA')\n",
    "\n",
    "uni_dots = [node for node in collab_graph.nodes() \n",
    "            if node in collab_df[[\"paper_1\", \"paper_2\"]].values]\n",
    "\n",
    "nx.draw_networkx_nodes(collab_graph, layout, nodelist = uni_dots, \n",
    "                       node_size = 30, node_color = '#AAAAAA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating eigenvector centrality to test\n",
    "\n",
    "dict(sorted(nx.eigenvector_centrality(collab_graph).items(), key = lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating in-degree centrality to test\n",
    "\n",
    "dict(sorted(nx.in_degree_centrality(collab_graph).items(), key = lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4702f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating betweenness centrality to test\n",
    "\n",
    "dict(filter(lambda value: value[1] > 0, \n",
    "            dict(sorted(nx.betweenness_centrality(collab_graph, normalized = True, endpoints = True).items(), \n",
    "                        key = lambda item: item[1], reverse = True)).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(20, 20))\n",
    "layout = nx.spring_layout(collab_graph, k = 0.7)\n",
    "\n",
    "nx.draw_networkx_edges(collab_graph, layout, edge_color = '#AAAAAA')\n",
    "\n",
    "uni_dots = [node for node in collab_graph.nodes() \n",
    "            if node in collab_df[[\"paper_1\", \"paper_2\"]].values]\n",
    "\n",
    "nx.draw_networkx_nodes(collab_graph, layout, nodelist = uni_dots, \n",
    "                       node_size = 30, node_color = '#AAAAAA')\n",
    "\n",
    "# Calculating different centralities\n",
    "\n",
    "eig_dict = dict(filter(lambda value: value[1] > 0.0005, \n",
    "                       dict(sorted(nx.eigenvector_centrality(collab_graph).items(), \n",
    "                                   key = lambda item: item[1], \n",
    "                                   reverse = True)).items()))\n",
    "\n",
    "inde_dict = dict(filter(lambda value: value[1] > 0.0005, \n",
    "                        dict(sorted(nx.in_degree_centrality(collab_graph).items(),\n",
    "                                    key = lambda item: item[1], \n",
    "                                    reverse = True)).items()))\n",
    "\n",
    "btn_dict = dict(filter(lambda value: value[1] > 0.0005, \n",
    "                       dict(sorted(nx.betweenness_centrality(collab_graph, normalized = True, endpoints = True).items(), \n",
    "                                   key = lambda item: item[1], \n",
    "                                   reverse = True)).items()))\n",
    "\n",
    "# Finding and mapping intersections\n",
    "\n",
    "intersection =  [node for node in collab_graph.nodes() \n",
    "                 if node in eig_dict.keys()\n",
    "                 if node in inde_dict.keys() \n",
    "                 if node in btn_dict.keys()]\n",
    "\n",
    "size_intersection = [value * 500000 for (node, value) in nx.in_degree_centrality(collab_graph).items() \n",
    "                     if node in intersection]\n",
    "\n",
    "nx.draw_networkx_nodes(collab_graph, layout, nodelist = intersection, \n",
    "                       node_size = size_intersection, node_color = 'purple', alpha = 0.3)\n",
    "\n",
    "nx.draw_networkx_labels(collab_graph, layout, \n",
    "                        labels = dict(zip(list(intersection), list(intersection))),\n",
    "                        font_size = 12)\n",
    "\n",
    "# Finding and mapping parts with higher in-degree + between centralities\n",
    "\n",
    "inde_btn = [node for node in collab_graph.nodes()\n",
    "            if node not in eig_dict.keys()\n",
    "            if node in inde_dict.keys()\n",
    "            if node in btn_dict.keys()]\n",
    "\n",
    "size_inde_btn = [value * 500000 for (node, value) in nx.in_degree_centrality(collab_graph).items() \n",
    "                 if node in inde_btn]\n",
    "\n",
    "nx.draw_networkx_nodes(collab_graph, layout, nodelist = inde_btn, \n",
    "                       node_size = size_inde_btn, node_color = 'aqua', alpha = 0.3)\n",
    "\n",
    "nx.draw_networkx_labels(collab_graph, layout, \n",
    "                        labels = dict(zip(list(inde_btn), list(inde_btn))),\n",
    "                        font_size = 10)\n",
    "\n",
    "# Finding and mapping parts with higher eigenvalue + in-degree centralities\n",
    "\n",
    "eig_inde = [node for node in collab_graph.nodes()\n",
    "            if node in eig_dict.keys()\n",
    "            if node in inde_dict.keys()\n",
    "            if node not in btn_dict.keys()]\n",
    "\n",
    "size_eig_inde = [value * 500000 for (node, value) in nx.in_degree_centrality(collab_graph).items() \n",
    "                 if node in eig_inde]\n",
    "\n",
    "nx.draw_networkx_nodes(collab_graph, layout, nodelist = eig_inde, \n",
    "                       node_size = size_eig_inde, node_color = 'yellow', alpha = 0.3)\n",
    "\n",
    "nx.draw_networkx_labels(collab_graph, layout, \n",
    "                        labels = dict(zip(list(eig_inde), list(eig_inde))),\n",
    "                        font_size = 10)\n",
    "\n",
    "# Finding and mapping parts with higher eigenvalue + betweenness centralities\n",
    "\n",
    "eig_btn = [node for node in collab_graph.nodes()\n",
    "           if node in eig_dict.keys()\n",
    "           if node not in inde_dict.keys()\n",
    "           if node in btn_dict.keys()]\n",
    "\n",
    "size_eig_btn = [value * 500000 for (node, value) in nx.in_degree_centrality(collab_graph).items() \n",
    "                if node in eig_btn]\n",
    "\n",
    "nx.draw_networkx_nodes(collab_graph, layout, nodelist = eig_btn, \n",
    "                       node_size = size_eig_btn, node_color = 'orange', alpha = 0.4)\n",
    "\n",
    "nx.draw_networkx_labels(collab_graph, layout, \n",
    "                        labels = dict(zip(list(eig_btn), list(eig_btn))),\n",
    "                        font_size = 10)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title(\"Collaborative papers\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating unique ID to title map for papers\n",
    "\n",
    "papers_map = {}\n",
    "for i in range(len(papers)):\n",
    "    papers_map[papers[i][\"result_id\"]] = papers[i][\"title\"]\n",
    "len(papers_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_map[\"XkWqVRksXioJ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c62181",
   "metadata": {},
   "source": [
    "## Fulltext collection\n",
    "\n",
    "- [Back to top](#Google-Scholar-paper-collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6535937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading saved metadata\n",
    "\n",
    "gs_authors = pd.read_json(\"./data/google-scholar/metadata/google-scholar-authors.json\")\n",
    "gs_papers = pd.read_json(\"./data/google-scholar/metadata/google-scholar-papers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9727341",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeae245",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60703541",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers[\"r_file_format\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ccc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers[\"r_title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b85ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading available fulltexts automatically\n",
    "\n",
    "parent_dir = \"/home/gereltuya/Downloads/spbu/ai-for-climate-action/data/google-scholar/papers/\"\n",
    "publishers = {}\n",
    "unavailable = []\n",
    "j = 1\n",
    "\n",
    "for i, row in gs_papers.iterrows():\n",
    "    if gs_papers[\"r_file_format\"][i] == [\"PDF\"]:\n",
    "        publisher = gs_papers[\"r_title\"][i][0]\n",
    "        paper = parent_dir + publisher + \"/\" + slugify(gs_papers[\"title\"][i], separator='_', lowercase=False) + \".pdf\"\n",
    "        if publisher in publishers.keys():\n",
    "            publishers[publisher][\"paper_count\"] += 1\n",
    "            publishers[publisher][\"paper_links\"].append(gs_papers[\"r_link\"][i][0])\n",
    "        else:\n",
    "            publishers[publisher] = {\"paper_count\": 1, \"paper_links\" : [gs_papers[\"r_link\"][i][0]]}\n",
    "            try:\n",
    "                os.mkdir(os.path.join(parent_dir, publisher))\n",
    "                print(\"Created directory:\", publisher, \"\\n\")\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "        if os.path.exists(paper):\n",
    "            print(str(j), \"--> Downloaded at:\", paper, \"\\n\")\n",
    "        else:\n",
    "            try:\n",
    "                ur.urlretrieve(gs_papers[\"r_link\"][i][0], paper)\n",
    "                shutil.copy(paper, parent_dir)\n",
    "                print(str(j), \"--> Downloaded at:\", paper, \"\\n\")\n",
    "            except:\n",
    "                print(str(j), \"--> Error:\", gs_papers[\"r_link\"][i][0], \"\\n\")\n",
    "                unavailable.append({\"link\": gs_papers[\"r_link\"][i][0], \"filename\": paper})\n",
    "        j += 1\n",
    "        \n",
    "# 157 fulltexts were downloaded automatically, log saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying URLs for fulltexts to be downloaded manually\n",
    "\n",
    "j = 1\n",
    "for i, row in gs_papers.iterrows():\n",
    "    if gs_papers[\"r_file_format\"][i] == [\"HTML\"]:\n",
    "        print(j, \"-->\", gs_papers[\"r_link\"][i][0], \"\\n\")\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c73807",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "for i, row in gs_papers.iterrows():\n",
    "    if gs_papers[\"r_file_format\"][i] == [\"DOC\"]:\n",
    "        print(j, \"-->\", gs_papers[\"r_link\"][i][0], \"\\n\")\n",
    "        j += 1\n",
    "        \n",
    "# 333 fulltexts were downloaded manually, log saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95ec33",
   "metadata": {},
   "source": [
    "## Unavailable papers\n",
    "\n",
    "- [Back to top](#Google-Scholar-paper-collection)\n",
    "\n",
    "### Not online:\n",
    "\n",
    "- https://www.academia.edu/download/67761160/nhess_2020_90.pdf\n",
    "- https://www.currentscience.ac.in/data/forthcoming/397.pdf\n",
    "- https://www.ijee.net/article_85007_6e39d36f6d36c1df57493a30a974f629.pdf\n",
    "- https://repository.unescap.org/bitstream/handle/20.500.12870/4694/ESCAP-1995-RP-Improving-access-women-formal-credit-financial-institutions.pdf?sequence=1\n",
    "- https://wellcomeopenresearch.s3.eu-west-1.amazonaws.com/manuscripts/20348/a99e9e04-e34b-4ce8-8b8e-fdfab2d44d45_17263_-_angela_mcbride_v3.pdf\n",
    "- http://www.scielo.org.co/pdf/dyna/v85n204/0012-7353-dyna-85-204-00194.pdf\n",
    "- https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/127/2015/01/Trusted-Innovation-Project-Executive-Summary.pdf\n",
    "- https://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/download/1644/2011\n",
    "\n",
    "### Not accessible:\n",
    "\n",
    "- https://asmedigitalcollection.asme.org/memagazineselect/article-abstract/142/04/36/1082911/Resilient-Technologies-Battling-Climate-ChangeAs?redirectedFrom=PDF\n",
    "- https://www.researchgate.net/publication/348363962_A_novel_framework_for_risk_assessment_and_resilience_of_critical_infrastructure_towards_climate_change\n",
    "- https://www.researchgate.net/publication/364769527_Cities_Allocating_climate_change_responsibilities_at_planetary_scale\n",
    "- https://www.tandfonline.com/doi/abs/10.1080/10106049.2022.2088861?journalCode=tgei20\n",
    "- https://meetingorganizer.copernicus.org/EGU22/EGU22-6568.html\n",
    "- https://dl.acm.org/doi/abs/10.4018/jats.2010100103\n",
    "- https://www.science.org/doi/10.1126/science.abj4216"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
