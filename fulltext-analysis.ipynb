{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cca665",
   "metadata": {},
   "source": [
    "# Fulltext analysis\n",
    "\n",
    "This notebook is a work in progress - to be updated soon...\n",
    "\n",
    "### To run this notebook, you need to install the following packages:\n",
    "\n",
    "- ```paperetl``` (Python)\n",
    "- ```GROBID``` (Java, [installation](https://grobid.readthedocs.io/en/latest/Install-Grobid/))\n",
    "\n",
    "### The notebook is sectioned into the following parts:\n",
    "\n",
    "- [Parsing PDFs](#Parsing-PDFs)\n",
    "- [Handling duplicates](#Handling-duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing PDFs\n",
    "\n",
    "# To use paperetl, active GROBID instance is needed\n",
    "# To use GROBID, JVM should also be installed\n",
    "# !wget https://github.com/kermitt2/grobid/archive/0.7.2.zip\n",
    "# !unzip 0.7.2.zip\n",
    "# !cd grobid-0.7.2\n",
    "# !./gradlew run\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee22e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing fulltexts\n",
    "\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f16686",
   "metadata": {},
   "source": [
    "## Parsing PDFs\n",
    "\n",
    "- [Back to top](#Fulltext-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e120de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing Google Scholar PDFs\n",
    "# !mkdir ./data/google-scholar/papers/json\n",
    "# !python -m paperetl.file data/google-scholar/papers json://data/google-scholar/papers/json\n",
    "\n",
    "# Parsing Springer PDFs\n",
    "# !mkdir ./data/springer/papers/json\n",
    "# !python -m paperetl.file data/springer/papers json://data/springer/papers/json\n",
    "\n",
    "# Parsing arXiv PDFs\n",
    "# !mkdir ./data/arxiv/papers/json\n",
    "# !python -m paperetl.file data/arxiv/papers json://data/arxiv/papers/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers = glob.glob(\"./data/google-scholar/papers/json/*.json\")\n",
    "s_papers = glob.glob(\"./data/springer/papers/json/*.json\")\n",
    "a_papers = glob.glob(\"./data/arxiv/papers/json/*.json\")\n",
    "\n",
    "print(\"Parsed {0}, {1}, {2} papers from Google Scholar (various publishers), Springer, and arXiv; respectively.\".format(len(gs_papers), len(s_papers), len(a_papers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a56960",
   "metadata": {},
   "source": [
    "## Handling duplicates\n",
    "\n",
    "- [Back to top](#Fulltext-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = []\n",
    "all_papers_map = {}\n",
    "sources = [\"google-scholar\", \"springer\", \"arxiv\"]\n",
    "\n",
    "for source in sources:\n",
    "    source_papers = glob.glob(\"./data/{0}/papers/json/*.json\".format(source))\n",
    "    for source_paper in source_papers:\n",
    "        with open(source_paper) as json_file:\n",
    "            paper = json.load(json_file)\n",
    "            location_pdf = \"-\".join(source_paper.split(\"-\")[:-1]).replace(\"/papers/json/\", \"/papers/\") + \".pdf\"\n",
    "            paper_dict = {\"source\": source, \"location_json\": source_paper, \"location_pdf\": location_pdf, \"details\": paper}\n",
    "            all_papers.append(paper_dict)\n",
    "            if paper[\"title\"] in all_papers_map.keys():\n",
    "                all_papers_map[paper[\"title\"]].append(paper_dict)\n",
    "            else:\n",
    "                all_papers_map[paper[\"title\"]] = [paper_dict]\n",
    "    print(\"Added papers from source:\", source)\n",
    "print(\"Total papers collected:\", len(all_papers))\n",
    "print(\"Total unique titles collected:\", len(all_papers_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c27596",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = []\n",
    "\n",
    "for title in all_papers_map.keys():\n",
    "    if len(all_papers_map[title]) > 1:\n",
    "        paper_sources = []\n",
    "        paper_versions = []\n",
    "        paper_pdfs = []\n",
    "        paper_jsons = []\n",
    "        for paper in all_papers_map[title]:\n",
    "            paper_sources.append(paper[\"source\"])\n",
    "            paper_versions.append(paper[\"details\"])\n",
    "            paper_pdfs.append(paper[\"location_pdf\"])\n",
    "            paper_jsons.append(paper[\"location_json\"])\n",
    "        duplicates.append({\"title\": all_papers_map[title][0][\"details\"][\"title\"], \"sources\": paper_sources, \"versions\": paper_versions, \"pdfs\": paper_pdfs, \"jsons\": paper_jsons})\n",
    "print(\"Separated {} duplicate papers for further analysis\".format(len(duplicates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_log = []\n",
    "\n",
    "for duplicate in duplicates:\n",
    "    duplicates_log.append({\"title\": duplicate[\"title\"], \"sources\": duplicate[\"sources\"], \"pdfs\": duplicate[\"pdfs\"], \"jsons\": duplicate[\"jsons\"], \"comment\": \"\"})\n",
    "    \n",
    "with open(\"./log/duplicates-log.json\", \"w\") as duplicates_log_file:\n",
    "    json.dump(duplicates_log, duplicates_log_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./log/duplicates-log-commented.json\", \"r\") as duplicates_log_file:\n",
    "    duplicates_log_commented = json.load(duplicates_log_file)\n",
    "    for duplicate in duplicates_log_commented:\n",
    "        print(duplicate[\"title\"], \"-->\", duplicate[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_papers = glob.glob(\"./data/google-scholar/papers/json/*.json\")\n",
    "s_papers = glob.glob(\"./data/springer/papers/json/*.json\")\n",
    "a_papers = glob.glob(\"./data/arxiv/papers/json/*.json\")\n",
    "\n",
    "print(\"After handling duplicates, {0}, {1}, {2} papers from Google Scholar (various publishers), Springer, and arXiv are left; respectively.\".format(len(gs_papers), len(s_papers), len(a_papers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d4c86",
   "metadata": {},
   "source": [
    "## Finding reviews and summaries\n",
    "\n",
    "- [Back to top](#Fulltext-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = []\n",
    "sources = [\"google-scholar\", \"springer\", \"arxiv\"]\n",
    "\n",
    "for source in sources:\n",
    "    source_papers = glob.glob(\"./data/{0}/papers/json/*.json\".format(source))\n",
    "    for source_paper in source_papers:\n",
    "        with open(source_paper) as json_file:\n",
    "            paper = json.load(json_file)\n",
    "            location_pdf = \"-\".join(source_paper.split(\"-\")[:-1]).replace(\"/papers/json/\", \"/papers/\") + \".pdf\"\n",
    "            paper_dict = {\"source\": source, \"location_json\": source_paper, \"location_pdf\": location_pdf, \"details\": paper}\n",
    "            all_papers.append(paper_dict)\n",
    "    print(\"Added papers from source:\", source)\n",
    "print(\"Total papers collected:\", len(all_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in all_papers:\n",
    "    if \"review\" in paper[\"details\"][\"title\"] or \"summary\" in paper[\"details\"][\"title\"] or \"survey\" in paper[\"details\"][\"title\"]:\n",
    "#         print(paper[\"details\"][\"title\"])\n",
    "        file_url = \"file:///home/gereltuya/Downloads/spbu/ai-for-climate-action\" + paper[\"location_pdf\"][1:]\n",
    "        print(file_url, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b86b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40774506",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers[0][\"details\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60e4fa",
   "metadata": {},
   "source": [
    "## Analyzing Springer abstracts with pyResearchInsights\n",
    "\n",
    "- [Back to top](#Fulltext-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyResearchInsights.Cleaner import cleaner_main\n",
    "\n",
    "abstracts_log_name = \"./LOGS/log/abstracts.txt\"\n",
    "status_logger_name = \"test_run\"\n",
    "cleaner_main(abstracts_log_name, status_logger_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac96061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyResearchInsights.Analyzer import analyzer_main\n",
    "\n",
    "abstracts_log_name = \"./LOGS/log/abstracts_CLEANED.txt\"\n",
    "status_logger_name = \"test_run\"\n",
    "analyzer_main(abstracts_log_name, status_logger_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyResearchInsights.NLP_Engine import nlp_engine_main\n",
    "abstracts_log_name = \"./LOGS/log/abstracts_CLEANED.txt\"\n",
    "status_logger_name = \"test_run\"\n",
    "nlp_engine_main(abstracts_log_name, status_logger_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
